Timer unit: 1e-06 s

File: Word2Vec.py
Function: batch_update at line 1069
Total time: 15.3755 s

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
  1069                                               def batch_update(self, anc_idx, pos_idx, neg_idx, learn_rate=1e-3):
  1070                                                   """Perform a batch update of all parameters based on the given sets
  1071                                                   of anchor/positive example/negative examples indices.
  1072                                                   """
  1073                                                   ada_smooth = 1e-3
  1074      1001         2589      2.6      0.0          lam_l2 = 1e-3
  1075      1001         1671      1.7      0.0          # Do new feedforward...
  1076      1001         1567      1.6      0.0          anc_idx = anc_idx.astype(np.int32)
  1077                                                   #print("pos_idx.shape: {0:s}, neg_idx.shape: {1:s}".format(str(pos_idx.shape),str(neg_idx.shape)))
  1078      1001         6762      6.8      0.0          pos_idx = pos_idx[:,np.newaxis]
  1079                                                   pn_idx = np.hstack((pos_idx, neg_idx)).astype(np.int32)
  1080      1001         6183      6.2      0.0          pn_sign = np.ones(pn_idx.shape)
  1081      1001        66297     66.2      0.4          pn_sign[:,0] = -1.0
  1082      1001        25832     25.8      0.2          L = np.zeros((1,))
  1083      1001        12440     12.4      0.1          # Do feedforward and backprop through the predictor/predictee tables
  1084      1001         4090      4.1      0.0          w2v_ff_bp(anc_idx, pn_idx, pn_sign, self.params['Wa'], self.params['Wc'], \
  1085                                                          self.params['b'], self.grads['Wa'], self.grads['Wc'], \
  1086      1001         2575      2.6      0.0                 self.grads['b'], L)
  1087      1001         2156      2.2      0.0          L = L[0]
  1088      1001      7669920   7662.3     49.9          # Apply gradients to (touched only) look-up-table parameters
  1089      1001        13667     13.7      0.1          a_mod_idx = np.unique(anc_idx.ravel())
  1090                                                   c_mod_idx = np.unique(pn_idx.ravel())
  1091      1001       104856    104.8      0.7          ag_update_2d(a_mod_idx, self.params['Wa'], self.grads['Wa'], \
  1092      1001       167280    167.1      1.1                  self.moms['Wa'], learn_rate, ada_smooth, lam_l2)
  1093      1001         3789      3.8      0.0          ag_update_2d(c_mod_idx, self.params['Wc'], self.grads['Wc'], \
  1094      1001       231346    231.1      1.5                  self.moms['Wc'], learn_rate, ada_smooth, lam_l2)
  1095      1001         2120      2.1      0.0          ag_update_1d(c_mod_idx, self.params['b'], self.grads['b'], \
  1096      1001      6907540   6900.6     44.9                  self.moms['b'], learn_rate, ada_smooth, lam_l2)
  1097      1001         7369      7.4      0.0          return L

